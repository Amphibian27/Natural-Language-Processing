{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Sentiment_Classification",
      "provenance": [],
      "collapsed_sections": [
        "wBtqXaXKfUuA",
        "id8a8gXMfUuj",
        "SLwgTIPefUul",
        "95pviBVjfUup",
        "Obynxw3jfUuu",
        "xxjiQs-kfUuw",
        "KeRuPw51fUuy",
        "FMZLwUA0fUu0",
        "rNf6FxexfUu_",
        "u14oiaqkfUvE",
        "VBDkeJzyfUvL",
        "8gA8eQ14fUvZ",
        "dZOXWmymfUvb",
        "T7YC6s6DfUve",
        "dqHKjWrJfUvh"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amphibian27/Natural-Language-Processing/blob/master/Sentiment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpndV98ifUr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category = FutureWarning)\n",
        "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category = UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaeyK0QKfUsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re \n",
        "\n",
        "import multiprocessing\n",
        "from nltk.tokenize import word_tokenize,WhitespaceTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "import string\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "import nltk.corpus.util\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAr_1R-dfUsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cores = multiprocessing.cpu_count() - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJuknHg9hkee",
        "colab_type": "text"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tuCOaWLNfUsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.read_csv(r'Usecase3_Dataset.csv',encoding = 'latin1')\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjo5aV9JfUsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2d24cf85-dbcd-4aeb-f206-69bf1bcd27cf"
      },
      "source": [
        "print(df1.columns)\n",
        "#Length of Dataframe\n",
        "print(len(df1))\n",
        "#Rows not containing any text data\n",
        "print(len(df1[df1[\"text\"].isna() == True]))#0 null values"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['airline_sentiment', 'airline', 'text'], dtype='object')\n",
            "14640\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL27RNU2K4Dv",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeeynpCSK6lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1['airline_sentiment'].value_counts().sort_values(ascending=False).iplot(kind='bar', yTitle='Number of Complaints', \n",
        "                                                                title='Number complaints in each product')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM9cd1JafUsW",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3csA4F_5fUsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing handles\n",
        "df1['cleaned_text'] = df1[\"text\"].apply(lambda row: re.sub(r'@[^\\s]+','',row))\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVngtDZAfUsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c8eec660-d401-4a10-d6a6-cca0b5e6e72d"
      },
      "source": [
        "#Remove all links\n",
        "df1['cleaned_text'] = df1[\"cleaned_text\"].apply(lambda row: re.sub(r'http[s]?://\\S+', '',str(row)))\n",
        "df1['cleaned_text'][7]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "' Really missed a prime opportunity for Men Without Hats parody, there. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA65csTXfUsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c8b31ae-9751-429a-9a65-d7559fc2ddfd"
      },
      "source": [
        "#Remove special characters excluding apostrophe\n",
        "df1['cleaned_text'] = df1[\"cleaned_text\"].apply(lambda row: re.sub(r\"[^A-Za-z0-9']+\", ' ',row))\n",
        "df1['cleaned_text'][27]"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\" do you miss me Don't worry we'll be together very soon \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K85AosIEFajn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ff1a3d7e-6395-42bf-d58e-4fe627492886"
      },
      "source": [
        "#remove leading and trailing blanks\n",
        "df1['cleaned_text'] = df1[\"cleaned_text\"].apply(lambda row: row.strip(' '))\n",
        "df1['cleaned_text'][27]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"do you miss me Don't worry we'll be together very soon\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0VcoMyKyLdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.to_csv('cleaned_data.csv')"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egV8tLz2fUsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8fb0a85-1412-4e95-f9e5-210622396bb2"
      },
      "source": [
        "df1.shape"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaO8cpgifUsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenize\n",
        "df1['cleaned_tokens'] = df1['cleaned_text'].apply(lambda row: row.split(' '))"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmaZUb3mfUso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "#Removing stopwords from tokens\n",
        "df1[\"cleaned_tokens\"] = df1[\"cleaned_tokens\"].apply(lambda row :[item for item in row if item not in stopword])\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB3-Iwo-fUsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "49c213d6-1290-4f0f-ce31-ecba7d03fded"
      },
      "source": [
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "def stemming(text):\n",
        "    text = [ps.stem(word) for word in text]\n",
        "    return text\n",
        "\n",
        "df1['lemmatized_tokens'] = df1['cleaned_tokens'].apply(lambda x: stemming(x))\n",
        "df1.head()##Results not satisfactory use wordnet lemmatizer"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_tokens</th>\n",
              "      <th>lemmatized_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>What said</td>\n",
              "      <td>[What, said]</td>\n",
              "      <td>[what, said]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>plus you've added commercials to the experienc...</td>\n",
              "      <td>[plus, added, commercials, experience, tacky]</td>\n",
              "      <td>[plu, ad, commerci, experi, tacki]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>I didn't today Must mean I need to take anothe...</td>\n",
              "      <td>[I, today, Must, mean, I, need, take, another,...</td>\n",
              "      <td>[I, today, must, mean, I, need, take, anoth, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>it's really aggressive to blast obnoxious ente...</td>\n",
              "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
              "      <td>[realli, aggress, blast, obnoxi, entertain, gu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>and it's a really big bad thing about it</td>\n",
              "      <td>[really, big, bad, thing]</td>\n",
              "      <td>[realli, big, bad, thing]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment  ...                                  lemmatized_tokens\n",
              "0           neutral  ...                                       [what, said]\n",
              "1          positive  ...                 [plu, ad, commerci, experi, tacki]\n",
              "2           neutral  ...  [I, today, must, mean, I, need, take, anoth, t...\n",
              "3          negative  ...  [realli, aggress, blast, obnoxi, entertain, gu...\n",
              "4          negative  ...                          [realli, big, bad, thing]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWbXrPeifUss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Join for wordnet lemmatization\n",
        "df1['cleaned_f']  = df1['cleaned_tokens'].apply(' '.join)\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM4hc0oHfUsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1df70080-ad9a-414e-939e-c839c5d80824"
      },
      "source": [
        "#lemmatization\n",
        "wnl = WordNetLemmatizer()\n",
        "df1[\"cleaned_f\"] = df1[\"cleaned_f\"].apply(lambda row: wnl.lemmatize(row))\n",
        "df1.head()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_tokens</th>\n",
              "      <th>lemmatized_tokens</th>\n",
              "      <th>cleaned_f</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>What said</td>\n",
              "      <td>[What, said]</td>\n",
              "      <td>[what, said]</td>\n",
              "      <td>What said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>plus you've added commercials to the experienc...</td>\n",
              "      <td>[plus, added, commercials, experience, tacky]</td>\n",
              "      <td>[plu, ad, commerci, experi, tacki]</td>\n",
              "      <td>plus added commercials experience tacky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>I didn't today Must mean I need to take anothe...</td>\n",
              "      <td>[I, today, Must, mean, I, need, take, another,...</td>\n",
              "      <td>[I, today, must, mean, I, need, take, anoth, t...</td>\n",
              "      <td>I today Must mean I need take another trip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>it's really aggressive to blast obnoxious ente...</td>\n",
              "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
              "      <td>[realli, aggress, blast, obnoxi, entertain, gu...</td>\n",
              "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>and it's a really big bad thing about it</td>\n",
              "      <td>[really, big, bad, thing]</td>\n",
              "      <td>[realli, big, bad, thing]</td>\n",
              "      <td>really big bad thing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment  ...                                          cleaned_f\n",
              "0           neutral  ...                                          What said\n",
              "1          positive  ...            plus added commercials experience tacky\n",
              "2           neutral  ...         I today Must mean I need take another trip\n",
              "3          negative  ...  really aggressive blast obnoxious entertainmen...\n",
              "4          negative  ...                               really big bad thing\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYHuVdU7L9E9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4488b9a1-359b-446b-a02e-64e5eeef63bc"
      },
      "source": [
        "#Tokenize again\n",
        "df1['cleaned_f'] = df1['cleaned_f'].apply(lambda row: row.split(' '))\n",
        "df1.head()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_tokens</th>\n",
              "      <th>lemmatized_tokens</th>\n",
              "      <th>cleaned_f</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>What said</td>\n",
              "      <td>[What, said]</td>\n",
              "      <td>[what, said]</td>\n",
              "      <td>[What, said]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>plus you've added commercials to the experienc...</td>\n",
              "      <td>[plus, added, commercials, experience, tacky]</td>\n",
              "      <td>[plu, ad, commerci, experi, tacki]</td>\n",
              "      <td>[plus, added, commercials, experience, tacky]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>I didn't today Must mean I need to take anothe...</td>\n",
              "      <td>[I, today, Must, mean, I, need, take, another,...</td>\n",
              "      <td>[I, today, must, mean, I, need, take, anoth, t...</td>\n",
              "      <td>[I, today, Must, mean, I, need, take, another,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>it's really aggressive to blast obnoxious ente...</td>\n",
              "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
              "      <td>[realli, aggress, blast, obnoxi, entertain, gu...</td>\n",
              "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>and it's a really big bad thing about it</td>\n",
              "      <td>[really, big, bad, thing]</td>\n",
              "      <td>[realli, big, bad, thing]</td>\n",
              "      <td>[really, big, bad, thing]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment  ...                                          cleaned_f\n",
              "0           neutral  ...                                       [What, said]\n",
              "1          positive  ...      [plus, added, commercials, experience, tacky]\n",
              "2           neutral  ...  [I, today, Must, mean, I, need, take, another,...\n",
              "3          negative  ...  [really, aggressive, blast, obnoxious, enterta...\n",
              "4          negative  ...                          [really, big, bad, thing]\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v3BwmdkfUty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67b86926-e30e-4139-922a-d44bc3fe6a79"
      },
      "source": [
        "#Filtering the empty strings from the list of tokens\n",
        "df1[\"cleaned_f\"] = df1[\"cleaned_f\"].apply(lambda row: list(filter(None,row)))\n",
        "df1.shape"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luoTdlOBfUt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Final join with clean text\n",
        "df1['cleaned_f']  = df1['cleaned_f'].apply(' '.join)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNf6FxexfUu_",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u14oiaqkfUvE",
        "colab_type": "text"
      },
      "source": [
        "## Dictionary based approach\n",
        "## Verification of Sentiments (Classification vs Vader)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lB3opPHQpPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "763ff9f3-ea69-4c5f-f53f-c9e124aea21d"
      },
      "source": [
        "# create training and testing vars\n",
        "y = df1.airline_sentiment\n",
        "X_train, X_test, y_train, y_test = train_test_split(df1, y, test_size=0.3,random_state=42)\n",
        "print(X_train.shape), print(y_train.shape)\n",
        "print (X_test.shape), print(y_test.shape)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10248, 8)\n",
            "(10248,)\n",
            "(4392, 8)\n",
            "(4392,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWpoH-f6KT4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d6fbccc-b898-487c-a9fa-edde6c49e41f"
      },
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zav4cxHUfUu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVvSU6RpfUvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "4d5e40ec-348d-4e97-ca5c-a379f95f3646"
      },
      "source": [
        "# Assigning Sentiments based on Polarity Score\n",
        "for item in X_test['text']:   \n",
        "    i = X_test.index.values[X_test['text'] == item]\n",
        "    scores = analyzer.polarity_scores(item)\n",
        "    if (scores['compound'] < 0.05) & (scores['compound'] > -0.05):\n",
        "        X_test.loc[i,'vader_Senti'] = 'neutral'\n",
        "    elif scores['compound'] <= -0.05:\n",
        "        X_test.loc[i,'vader_Senti'] = 'negative'\n",
        "    elif scores['compound'] >= 0.05:\n",
        "        X_test.loc[i,'vader_Senti'] = 'positive'"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iks8sOYZfUvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding labels \n",
        "le = LabelEncoder()\n",
        "vader_in = le.fit_transform(X_test['airline_sentiment'])\n",
        "vader_out = le.transform(X_test['vader_Senti'])"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCa8PAF-fUvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc561445-42f5-4a3b-98a2-f66dbe5a5bc1"
      },
      "source": [
        "accuracy_score(y_true = vader_out, y_pred  = vader_in)\n",
        "#Dictionary based approach for benchmarking, received  53% accuracy "
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5371129326047359"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdfrAIQfWJ5E",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning based approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pFHk8uyfUvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer()\n",
        "x_train = cv.fit_transform(X_train['cleaned_f'])\n",
        "x_test = cv.transform(X_test['cleaned_f'])"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkyk0xBwfUvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfTransformer()\n",
        "x_train = tfidf.fit_transform(x_train)\n",
        "x_test = tfidf.transform(x_test)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbo7_K-xfUvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting sparse matrix to dense matrix\n",
        "x_train = x_train.todense()\n",
        "x_test = x_test.todense()"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gA8eQ14fUvZ",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CfGf_vBfUvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "73ed846f-225a-440a-c4ee-2877c863cf8c"
      },
      "source": [
        "#DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFiHCUOISaVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "97b50eb1-1abb-47c9-9065-3ba4eefbc2cd"
      },
      "source": [
        "X_test['Decision Tree'] = clf.predict(x_test)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phYgj2haUJuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding labels \n",
        "le = LabelEncoder()\n",
        "actual = le.fit_transform(X_test['airline_sentiment'])\n",
        "predicted = le.transform(X_test['Decision Tree'])"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5N8ubJSUSeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dc21e7f-ef22-4d1b-8235-f852a3651eaa"
      },
      "source": [
        "accuracy_score(y_true = actual, y_pred  = predicted)\n",
        "#Decision tree managed to improve accuracy from 54% to 70%"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7019581056466302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZOXWmymfUvb",
        "colab_type": "text"
      },
      "source": [
        "### XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZyRd-1PfUvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a8cc3b2f-dc20-4991-dcb5-a4be916a8ba3"
      },
      "source": [
        "#Classification using XGBoost Classifier\n",
        "xgb = XGBClassifier(random_state = 21,n_jobs = cores)\n",
        "xgb.fit(x_train,y_train)\n",
        "X_test['XGB'] = xgb.predict(x_test)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbTMMMmWtHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding labels \n",
        "le = LabelEncoder()\n",
        "actual = le.fit_transform(X_test['airline_sentiment'])\n",
        "predicted = le.transform(X_test['XGB'])"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp4btvGsWv6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19cdede8-a264-4192-9a94-22e8deb5c895"
      },
      "source": [
        "accuracy_score(y_true = actual, y_pred  = predicted)\n",
        "#Decision tree managed to improve accuracy from 54% to 70%"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7015027322404371"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7YC6s6DfUve",
        "colab_type": "text"
      },
      "source": [
        "### Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh9iaIJifUve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3e02aae9-ee05-4943-edfc-07f9c115f531"
      },
      "source": [
        "#Classification Using Support Vector Classifier\n",
        "clfSVM = LinearSVC()\n",
        "clfSVM.fit(x_train,y_train)\n",
        "X_test['SVM'] = clfSVM.predict(x_test)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RAt-686Y6Im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding labels \n",
        "le = LabelEncoder()\n",
        "actual = le.fit_transform(X_test['airline_sentiment'])\n",
        "predicted = le.transform(X_test['SVM'])"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFWfOrdY6Ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82bd3eac-1b12-4af9-fbee-4173c0d6b34e"
      },
      "source": [
        "accuracy_score(y_true = actual, y_pred  = predicted)\n",
        "#Decision tree managed to improve accuracy from 54% to 70%"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5412112932604736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqHKjWrJfUvh",
        "colab_type": "text"
      },
      "source": [
        "### Deeplearning - Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZMvgm6w-j2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence  import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import SpatialDropout1D \n",
        "from keras.callbacks import EarlyStopping \n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_ajHQ_RH73u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a41a62c4-f582-45aa-cc0d-1e6f01f4ecd2"
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 10000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 128\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(df1['cleaned_f'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('%s unique tokens.' % len(word_index))"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13312 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjTaFi5RIgDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0dc94ce-b44d-4755-ee11-88c1021551c7"
      },
      "source": [
        "X = tokenizer.texts_to_sequences(df1['cleaned_f'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (14640, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip1EZfccImiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dab763a-cda2-40ec-e4de-0f7d40850455"
      },
      "source": [
        "Y = pd.get_dummies(df1['airline_sentiment']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (14640, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hco7UVJEIuN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "474be6ad-af2a-4aaa-f9d5-3c36e1bdb24d"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.30, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10248, 250) (10248, 3)\n",
            "(4392, 250) (4392, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEga7c-5I2el",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "ee94a9b1-86af-41b2-e766-29c6a332ec9b"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9223 samples, validate on 1025 samples\n",
            "Epoch 1/50\n",
            "9223/9223 [==============================] - 74s 8ms/step - loss: 0.7828 - accuracy: 0.6685 - val_loss: 0.6372 - val_accuracy: 0.7444\n",
            "Epoch 2/50\n",
            "9223/9223 [==============================] - 75s 8ms/step - loss: 0.4979 - accuracy: 0.8100 - val_loss: 0.5432 - val_accuracy: 0.7737\n",
            "Epoch 3/50\n",
            "9223/9223 [==============================] - 75s 8ms/step - loss: 0.3518 - accuracy: 0.8695 - val_loss: 0.5535 - val_accuracy: 0.7717\n",
            "Epoch 4/50\n",
            "9223/9223 [==============================] - 75s 8ms/step - loss: 0.2707 - accuracy: 0.9037 - val_loss: 0.6225 - val_accuracy: 0.7717\n",
            "Epoch 5/50\n",
            "9223/9223 [==============================] - 75s 8ms/step - loss: 0.2093 - accuracy: 0.9251 - val_loss: 0.6715 - val_accuracy: 0.7610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKI2NNYIJ2ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "db607d2f-05c1-46b2-f924-4ed988a1a62d"
      },
      "source": [
        "accr = model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4392/4392 [==============================] - 8s 2ms/step\n",
            "Test set\n",
            "  Loss: 0.681\n",
            "  Accuracy: 0.779\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}