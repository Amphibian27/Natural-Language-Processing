{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpndV98ifUr-"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = FutureWarning)\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaeyK0QKfUsC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os # Operating system\n",
    "import re #Regular Expression\n",
    "import gensim\n",
    "import multiprocessing\n",
    "from nltk.tokenize import word_tokenize,WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from string import digits\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "import string\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.corpus.util\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import cufflinks as cf\n",
    "import matplotlib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAr_1R-dfUsF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count() - 1\n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJuknHg9hkee"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuCOaWLNfUsH",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4752, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add consumer data here\n",
    "df1 = pd.read_csv(r'Commerical Relabeld data_FINAL.csv',encoding = 'latin1')\n",
    "df1.head()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Verbatim', 'CustomerSentiment(New)', 'Sat_Metric_OverallQoSBox',\n",
       "       'IsResolved', 'VerbatimLength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verbatim</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Sat_Metric_OverallQoSBox</th>\n",
       "      <th>IsResolved</th>\n",
       "      <th>VerbatimLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$5,000 Azure credit for non profit has not bee...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1) Quick response to submitted request(2) Kno...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Verbatim Sentiments  \\\n",
       "0  $5,000 Azure credit for non profit has not bee...   Negative   \n",
       "1  (1) Quick response to submitted request(2) Kno...   Positive   \n",
       "\n",
       "  Sat_Metric_OverallQoSBox IsResolved  VerbatimLength  \n",
       "0                       BB         No             202  \n",
       "1                       TB        Yes             113  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing index cols with rename() \n",
    "df1.rename(columns = {\"ï»¿Verbatim\": \"Verbatim\",\"CustomerSentiment(New)\": \"Sentiments\"},\n",
    "                    inplace = True) \n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Xjo5aV9JfUsO",
    "outputId": "f607ef6f-7016-4a11-9428-f0e7b1520a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Verbatim', 'Sentiments', 'Sat_Metric_OverallQoSBox', 'IsResolved',\n",
      "       'VerbatimLength'],\n",
      "      dtype='object')\n",
      "4752\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)\n",
    "#Length of Dataframe\n",
    "print(len(df1))\n",
    "#Rows not containing any text data\n",
    "print(len(df1[df1[\"Verbatim\"].isna() == True]))#0 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1[['IsResolved', 'Sat_Metric_OverallQoSBox','VerbatimLength']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jL27RNU2K4Dv"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "EkT92srzVq04",
    "outputId": "1d382b23-9ec0-4a30-d47d-41012eeaad41",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1['Sentiments'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    3079\n",
       "Negative    1198\n",
       "Neutral      475\n",
       "Name: Sentiments, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting percentage for various classes in a column\n",
    "df1.Sentiments.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dM9cd1JafUsW"
   },
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "def clean_sentences(text):\n",
    "    #Input: Sentences\n",
    "    #Output: cleaned sentence by removing numbers, stopwords, punctuations, single alphabet, and change single uppercase to lowercase letters\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = text.translate(remove_digits)    \n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = [s.lower() for s in text]\n",
    "    #text = [s for s in text if s not in set(stopwords.words('english'))]\n",
    "    text = [s for s in text if len(s)>1]\n",
    "    #text = ' '.join(text)\n",
    "    return text   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cleaned_test'] =df1['Verbatim'].apply(lambda x: clean_sentences(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmaZUb3mfUso"
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "newStopWords = ['support','microsoft','problem','issue','service','namepii']\n",
    "stopwords.extend(newStopWords) #Joining stopwords and newstopwords\n",
    "\n",
    "#Removing stopwords from tokens\n",
    "df1[\"cleaned_test\"] = df1[\"cleaned_test\"].apply(lambda row :[item for item in row if item not in stopwords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWbXrPeifUss"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verbatim</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Sat_Metric_OverallQoSBox</th>\n",
       "      <th>IsResolved</th>\n",
       "      <th>VerbatimLength</th>\n",
       "      <th>cleaned_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$5,000 Azure credit for non profit has not bee...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>202</td>\n",
       "      <td>azure credit non profit applied new azure acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1) Quick response to submitted request(2) Kno...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>113</td>\n",
       "      <td>quick response submitted request knowledgeable...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Verbatim Sentiments  \\\n",
       "0  $5,000 Azure credit for non profit has not bee...   Negative   \n",
       "1  (1) Quick response to submitted request(2) Kno...   Positive   \n",
       "\n",
       "  Sat_Metric_OverallQoSBox IsResolved  VerbatimLength  \\\n",
       "0                       BB         No             202   \n",
       "1                       TB        Yes             113   \n",
       "\n",
       "                                        cleaned_test  \n",
       "0  azure credit non profit applied new azure acco...  \n",
       "1  quick response submitted request knowledgeable...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join for wordnet lemmatization\n",
    "df1['cleaned_test']  = df1['cleaned_test'].apply(' '.join)\n",
    "df1.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VerbatimLength</th>\n",
       "      <th>IsResolved_No</th>\n",
       "      <th>IsResolved_UNKNOWN</th>\n",
       "      <th>IsResolved_Yes</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_BB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_MB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_TB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_UNKNOWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VerbatimLength  IsResolved_No  IsResolved_UNKNOWN  IsResolved_Yes  \\\n",
       "0             202              1                   0               0   \n",
       "1             113              0                   0               1   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_BB  Sat_Metric_OverallQoSBox_MB  \\\n",
       "0                            1                            0   \n",
       "1                            0                            0   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_TB  Sat_Metric_OverallQoSBox_UNKNOWN  \n",
       "0                            0                                 0  \n",
       "1                            1                                 0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dum=pd.get_dummies(df2, dummy_na=False)\n",
    "data_dum.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VerbatimLength</th>\n",
       "      <th>IsResolved_No</th>\n",
       "      <th>IsResolved_UNKNOWN</th>\n",
       "      <th>IsResolved_Yes</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_BB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_MB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_TB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_UNKNOWN</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>cleaned_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>azure credit non profit applied new azure acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>quick response submitted request knowledgeable...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VerbatimLength  IsResolved_No  IsResolved_UNKNOWN  IsResolved_Yes  \\\n",
       "0             202              1                   0               0   \n",
       "1             113              0                   0               1   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_BB  Sat_Metric_OverallQoSBox_MB  \\\n",
       "0                            1                            0   \n",
       "1                            0                            0   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_TB  Sat_Metric_OverallQoSBox_UNKNOWN Sentiments  \\\n",
       "0                            0                                 0   Negative   \n",
       "1                            1                                 0   Positive   \n",
       "\n",
       "                                        cleaned_test  \n",
       "0  azure credit non profit applied new azure acco...  \n",
       "1  quick response submitted request knowledgeable...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f = pd.concat([data_dum.reset_index(drop=True), df1[['Sentiments','cleaned_test']]], axis=1)\n",
    "df_f.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    0.647938\n",
       "Negative    0.252104\n",
       "Neutral     0.099958\n",
       "Name: Sentiments, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.Sentiments.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_f.Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_f=df_f.drop(['Sentiments'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "1lB3opPHQpPh",
    "outputId": "763ff9f3-ea69-4c5f-f53f-c9e124aea21d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3326, 10) (3326,)\n",
      "(1426, 10) (1426,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VerbatimLength</th>\n",
       "      <th>IsResolved_No</th>\n",
       "      <th>IsResolved_UNKNOWN</th>\n",
       "      <th>IsResolved_Yes</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_BB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_MB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_TB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_UNKNOWN</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>cleaned_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>timeline resolution time around long spanned w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>helpful got past misunderstandings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VerbatimLength  IsResolved_No  IsResolved_UNKNOWN  IsResolved_Yes  \\\n",
       "3880             240              0                   0               1   \n",
       "1188              56              0                   0               1   \n",
       "\n",
       "      Sat_Metric_OverallQoSBox_BB  Sat_Metric_OverallQoSBox_MB  \\\n",
       "3880                            0                            1   \n",
       "1188                            0                            1   \n",
       "\n",
       "      Sat_Metric_OverallQoSBox_TB  Sat_Metric_OverallQoSBox_UNKNOWN  \\\n",
       "3880                            0                                 0   \n",
       "1188                            0                                 0   \n",
       "\n",
       "     Sentiments                                       cleaned_test  \n",
       "3880   Negative  timeline resolution time around long spanned w...  \n",
       "1188    Neutral                 helpful got past misunderstandings  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_f, y, test_size=0.30,random_state=42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    2151\n",
       "Negative     828\n",
       "Neutral      347\n",
       "Name: Sentiments, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% distribution on Pos/neg/neu in full sample data\n",
    "X_train.Sentiments.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# % distribution on pos/neg/neu after oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample=RandomOverSampler(sampling_strategy={'Positive':2152,'Negative':900,'Neutral':600})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=oversample.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3652, 10) (3652,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    0.589266\n",
       "Negative    0.246440\n",
       "Neutral     0.164294\n",
       "Name: Sentiments, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.Sentiments.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversamplesmote=SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,y_train=oversample.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    0.589266\n",
       "Negative    0.246440\n",
       "Neutral     0.164294\n",
       "Name: Sentiments, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.Sentiments.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    #input: file\n",
    "    #output: word to 50d vector mapping output\n",
    "    with open(glove_file, encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "word_to_vec_map = read_glove_vecs('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(ds, word_to_vec_map):\n",
    "    #input: Series, and word_to_vec_map of size(vocab_size,50)\n",
    "    #output: returns shape of (len(ds), 50)\n",
    "    traintest_X = []\n",
    "    for sentence in tqdm(ds.values):\n",
    "        sequence_words = np.zeros((word_to_vec_map['worst'].shape))\n",
    "        for word in sentence.split():\n",
    "            if word in word_to_vec_map.keys():\n",
    "                temp_X = word_to_vec_map[word]\n",
    "            else:\n",
    "                temp_X = word_to_vec_map['#']\n",
    "            sequence_words+=(temp_X)/len(sentence)\n",
    "        traintest_X.append(sequence_words)\n",
    "    return np.array(traintest_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3652/3652 [00:00<00:00, 14655.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1426/1426 [00:00<00:00, 20344.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "Train_wv_X = prepare_sequence(X_train['cleaned_test'], word_to_vec_map)\n",
    "Test_wv_X = prepare_sequence(X_test['cleaned_test'], word_to_vec_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VerbatimLength</th>\n",
       "      <th>IsResolved_No</th>\n",
       "      <th>IsResolved_UNKNOWN</th>\n",
       "      <th>IsResolved_Yes</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_BB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_MB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_TB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_UNKNOWN</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>cleaned_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>timeline resolution time around long spanned w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>helpful got past misunderstandings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>ryan sylvester one staff whose name catch help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>would liked could solved quickly agent resolve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>node vm failed would appreciated notified happ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VerbatimLength  IsResolved_No  IsResolved_UNKNOWN  IsResolved_Yes  \\\n",
       "0             240              0                   0               1   \n",
       "1              56              0                   0               1   \n",
       "2             339              0                   0               1   \n",
       "3             164              0                   0               1   \n",
       "4             155              0                   0               1   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_BB  Sat_Metric_OverallQoSBox_MB  \\\n",
       "0                            0                            1   \n",
       "1                            0                            1   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            1   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_TB  Sat_Metric_OverallQoSBox_UNKNOWN Sentiments  \\\n",
       "0                            0                                 0   Negative   \n",
       "1                            0                                 0    Neutral   \n",
       "2                            1                                 0   Positive   \n",
       "3                            1                                 0    Neutral   \n",
       "4                            0                                 0   Negative   \n",
       "\n",
       "                                        cleaned_test  \n",
       "0  timeline resolution time around long spanned w...  \n",
       "1                 helpful got past misunderstandings  \n",
       "2  ryan sylvester one staff whose name catch help...  \n",
       "3  would liked could solved quickly agent resolve...  \n",
       "4  node vm failed would appreciated notified happ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(['cleaned_test'],axis=True)\n",
    "X_test=X_test.drop(['cleaned_test'],axis=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=X_train.drop(['Sentiments'],axis=True)\n",
    "X_test1=X_test.drop(['Sentiments'],axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f = np.concatenate([X_train1.values, Train_wv_X], axis=-1)\n",
    "X_test_f = np.concatenate([X_test1.values, Test_wv_X], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNf6FxexfUu_"
   },
   "source": [
    "# Sentiment Analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7YC6s6DfUve"
   },
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "nh9iaIJifUve",
    "outputId": "3e02aae9-ee05-4943-edfc-07f9c115f531"
   },
   "outputs": [],
   "source": [
    "#Classification Using Support Vector Classifier\n",
    "clfSVM = LinearSVC()\n",
    "clfSVM.fit(X_train_f,y_train)\n",
    "X_test['SVM'] = clfSVM.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RAt-686Y6Im"
   },
   "outputs": [],
   "source": [
    "#Encoding labels \n",
    "le = LabelEncoder()\n",
    "actual = le.fit_transform(X_test['Sentiments'])\n",
    "predicted = le.transform(X_test['SVM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qVFWfOrdY6Ou",
    "outputId": "82bd3eac-1b12-4af9-fbee-4173c0d6b34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set  Accuracy: 0.781\n",
      "[[170 130  70]\n",
      " [ 20  38  70]\n",
      " [  3  20 905]]\n",
      "[0.45945946 0.296875   0.97521552]\n",
      "[0.88082902 0.20212766 0.86602871]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "#print(accuracy_score(y_true = actual, y_pred  = predicted))\n",
    "print('Test set  Accuracy: {:0.3f}'.format(accuracy_score(y_true = actual, y_pred  = predicted)))\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_true = actual, y_pred  = predicted))\n",
    "# Recall\n",
    "print(recall_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "# Precision\n",
    "print(precision_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "#93.9 % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Using#naive bayes algorithm\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_f,y_train)\n",
    "X_test['NB'] = model.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels \n",
    "le = LabelEncoder()\n",
    "actual = le.fit_transform(X_test['Sentiments'])\n",
    "predicted = le.transform(X_test['NB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5280504908835905\n",
      "Test set  Accuracy: 0.528\n",
      "[[321  38  11]\n",
      " [ 92  24  12]\n",
      " [459  61 408]]\n",
      "[0.86756757 0.1875     0.43965517]\n",
      "[0.36811927 0.19512195 0.94663573]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "print(accuracy_score(y_true = actual, y_pred  = predicted))\n",
    "print('Test set  Accuracy: {:0.3f}'.format(accuracy_score(y_true = actual, y_pred  = predicted)))\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_true = actual, y_pred  = predicted))\n",
    "# Recall\n",
    "print(recall_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "# Precision\n",
    "print(precision_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "#51.7% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.37      0.87      0.52       370\n",
      "     Neutral       0.20      0.19      0.19       128\n",
      "    Positive       0.95      0.44      0.60       928\n",
      "\n",
      "    accuracy                           0.53      1426\n",
      "   macro avg       0.50      0.50      0.44      1426\n",
      "weighted avg       0.73      0.53      0.54      1426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual,predicted,target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Earlier result\n",
    "# [0.75       0.31932773 0.43521595]\n",
    "# [0.53846154 0.09223301 0.84154176]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Using#Logistic  algorithm\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_f,y_train)\n",
    "X_test['LR'] = model.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels \n",
    "le = LabelEncoder()\n",
    "actual = le.fit_transform(X_test['Sentiments'])\n",
    "predicted = le.transform(X_test['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set  Accuracy: 0.813\n",
      "[[259  43  68]\n",
      " [ 46   9  73]\n",
      " [ 26  10 892]]\n",
      "[0.7       0.0703125 0.9612069]\n",
      "[0.78247734 0.14516129 0.86350436]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy from Iteration -1\n",
    "#print(accuracy_score(y_true = actual, y_pred  = predicted))\n",
    "print('Test set  Accuracy: {:0.3f}'.format(accuracy_score(y_true = actual, y_pred  = predicted)))\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_true = actual, y_pred  = predicted))\n",
    "# Recall\n",
    "print(recall_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "# Precision\n",
    "print(precision_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "#82.7% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('classifier',RandomForestClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf=GridSearchCV(pipe,param_grid=param_grid,cv=5,verbose=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.4min finished\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_f,y_train)\n",
    "X_test['LR_grid'] = model.predict(X_test_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('classifier',\n",
       "                 RandomForestClassifier(max_features=21, n_estimators=70))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=4.3, penalty='l1',\n",
    "                                    solver='liblinear')\n",
    "model.fit(X_train_f,y_train)\n",
    "X_test['GridLR'] = model.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels \n",
    "le = LabelEncoder()\n",
    "actual = le.fit_transform(X_test['Sentiments'])\n",
    "predicted = le.transform(X_test['GridLR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set  Accuracy: 0.852\n",
      "[[303  30  37]\n",
      " [ 46  29  53]\n",
      " [ 24  21 883]]\n",
      "[0.81891892 0.2265625  0.95150862]\n",
      "[0.81233244 0.3625     0.90750257]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy after parameter tuning\n",
    "#print(accuracy_score(y_true = actual, y_pred  = predicted))\n",
    "print('Test set  Accuracy: {:0.3f}'.format(accuracy_score(y_true = actual, y_pred  = predicted)))\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_true = actual, y_pred  = predicted))\n",
    "# Recall\n",
    "print(recall_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "# Precision\n",
    "print(precision_score(y_true = actual, y_pred  = predicted, average=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_features=21, n_estimators=80)\n",
    "model.fit(X_train_f,y_train)\n",
    "X_test['GridLR'] = model.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels \n",
    "le = LabelEncoder()\n",
    "actual = le.fit_transform(X_test['Sentiments'])\n",
    "predicted = le.transform(X_test['GridLR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set  Accuracy: 0.846\n",
      "[[296   9  65]\n",
      " [ 49   9  70]\n",
      " [ 27   0 901]]\n",
      "[0.8        0.0703125  0.97090517]\n",
      "[0.79569892 0.5        0.86969112]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "#print(accuracy_score(y_true = actual, y_pred  = predicted))\n",
    "print('Test set  Accuracy: {:0.3f}'.format(accuracy_score(y_true = actual, y_pred  = predicted)))\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_true = actual, y_pred  = predicted))\n",
    "# Recall\n",
    "print(recall_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "# Precision\n",
    "print(precision_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "# 94.0% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\MyDrive\\\\PythonWs\\\\Commercial V2'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.to_csv('30_percent_test_sample_fin.csv')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification using XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state = 21,n_jobs = cores)\n",
    "xgb.fit(X_train_f,y_train)\n",
    "X_test['XGB'] = xgb.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test['XGB'] = xgb.predict(x_test)\n",
    "#Encoding labels \n",
    "le = LabelEncoder()\n",
    "actual = le.fit_transform(X_test['Sentiments'])\n",
    "predicted = le.transform(X_test['XGB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set  Accuracy: 0.852\n",
      "[[304  15  51]\n",
      " [ 52  17  59]\n",
      " [ 29   5 894]]\n",
      "[0.82162162 0.1328125  0.96336207]\n",
      "[0.78961039 0.45945946 0.89043825]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy for XG Boost without finetuning\n",
    "#print(accuracy_score(y_true = actual, y_pred  = predicted))\n",
    "print('Test set  Accuracy: {:0.3f}'.format(accuracy_score(y_true = actual, y_pred  = predicted)))\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_true = actual, y_pred  = predicted))\n",
    "# Recall\n",
    "print(recall_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "# Precision\n",
    "print(precision_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "#81% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('thirty_percent_for_misclclass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost (highly tuned XGBoost Classifier)\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='objective=multi:softmax',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed: 11.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x000002718B19E820>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.02,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, mis...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None, silent=True,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=4,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=1001, verbose=3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, n_jobs=4, cv=skf.split(X_train_f,y_train), verbose=3, random_state=1001 )\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train_f, y_train)\n",
    "#timer(start_time)# timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['XGB_CV'] = random_search.predict(X_test_f)\n",
    "#Encoding labels \n",
    "le = LabelEncoder()\n",
    "actual = le.fit_transform(X_test['Sentiments'])\n",
    "predicted = le.transform(X_test['XGB_CV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set  Accuracy: 0.858\n",
      "[[309  14  47]\n",
      " [ 52  20  56]\n",
      " [ 27   6 895]]\n",
      "[0.83513514 0.15625    0.96443966]\n",
      "[0.79639175 0.5        0.89679359]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "#print(accuracy_score(y_true = actual, y_pred  = predicted))\n",
    "print('Test set  Accuracy: {:0.3f}'.format(accuracy_score(y_true = actual, y_pred  = predicted)))\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_true = actual, y_pred  = predicted))\n",
    "# Recall\n",
    "print(recall_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "# Precision\n",
    "print(precision_score(y_true = actual, y_pred  = predicted, average=None))\n",
    "#81% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "This is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-abhkumar\\Anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning:\n",
      "\n",
      "Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for predictions\n",
    "test_csv = pd.read_csv('Production_commercial 6 columns.csv')\n",
    "#test_csv['Verbatim'] = test_csv.fillna({'Verbatim':''})\n",
    "test_csv=test_csv[test_csv['Verbatim'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentNumber</th>\n",
       "      <th>Verbatim</th>\n",
       "      <th>Sat_Metric_OverallQoSBox</th>\n",
       "      <th>Isresolved</th>\n",
       "      <th>Verbatim_Length</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1501886938</td>\n",
       "      <td>Support request No. : \"Phonenumberpii\"    ...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>203</td>\n",
       "      <td>12:20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>This is not the fault of the service depart...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>401</td>\n",
       "      <td>00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>This is not the fault of the service depart...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>398</td>\n",
       "      <td>29:34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>&lt;**EMAIL ADDRESS REMOVED**&gt;  {Namepii} {Name...</td>\n",
       "      <td>TB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>284</td>\n",
       "      <td>00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>- average: There were no strong time constrai...</td>\n",
       "      <td>MB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>289</td>\n",
       "      <td>00:00.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IncidentNumber                                           Verbatim  \\\n",
       "0     1501886938      Support request No. : \"Phonenumberpii\"    ...   \n",
       "1       1.20E+14     This is not the fault of the service depart...   \n",
       "2       1.20E+14     This is not the fault of the service depart...   \n",
       "3       1.20E+14    <**EMAIL ADDRESS REMOVED**>  {Namepii} {Name...   \n",
       "4       1.20E+14   - average: There were no strong time constrai...   \n",
       "\n",
       "  Sat_Metric_OverallQoSBox Isresolved  Verbatim_Length     date  \n",
       "0                       BB         No              203  12:20.0  \n",
       "1                       BB         No              401  00:00.0  \n",
       "2                       BB         No              398  29:34.0  \n",
       "3                       TB        Yes              284  00:00.0  \n",
       "4                       MB        Yes              289  00:00.0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['cleaned_test'] =test_csv['Verbatim'].apply(lambda x: clean_sentences(x))\n",
    "test_csv[\"cleaned_test\"] = test_csv[\"cleaned_test\"].apply(lambda row :[item for item in row if item not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentNumber</th>\n",
       "      <th>Verbatim</th>\n",
       "      <th>Sat_Metric_OverallQoSBox</th>\n",
       "      <th>Isresolved</th>\n",
       "      <th>Verbatim_Length</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1501886938</td>\n",
       "      <td>Support request No. : \"Phonenumberpii\"    ...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>203</td>\n",
       "      <td>12:20.0</td>\n",
       "      <td>request phonenumberpii closing utc closing req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>This is not the fault of the service depart...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>401</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>fault department opinion faulty design surface...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IncidentNumber                                           Verbatim  \\\n",
       "0     1501886938      Support request No. : \"Phonenumberpii\"    ...   \n",
       "1       1.20E+14     This is not the fault of the service depart...   \n",
       "\n",
       "  Sat_Metric_OverallQoSBox Isresolved  Verbatim_Length     date  \\\n",
       "0                       BB         No              203  12:20.0   \n",
       "1                       BB         No              401  00:00.0   \n",
       "\n",
       "                                        cleaned_test  \n",
       "0  request phonenumberpii closing utc closing req...  \n",
       "1  fault department opinion faulty design surface...  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv['cleaned_test']  = test_csv['cleaned_test'].apply(' '.join)\n",
    "test_csv.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verbatim_Length</th>\n",
       "      <th>Isresolved_No</th>\n",
       "      <th>Isresolved_UNKNOWN</th>\n",
       "      <th>Isresolved_Yes</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_BB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_MB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_TB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_UNKNOWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Verbatim_Length  Isresolved_No  Isresolved_UNKNOWN  Isresolved_Yes  \\\n",
       "0              203              1                   0               0   \n",
       "1              401              1                   0               0   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_BB  Sat_Metric_OverallQoSBox_MB  \\\n",
       "0                            1                            0   \n",
       "1                            1                            0   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_TB  Sat_Metric_OverallQoSBox_UNKNOWN  \n",
       "0                            0                                 0  \n",
       "1                            0                                 0  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx=test_csv[['Isresolved', 'Sat_Metric_OverallQoSBox','Verbatim_Length']]\n",
    "data_dum1=pd.get_dummies(dfx, dummy_na=False)\n",
    "data_dum1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verbatim_Length</th>\n",
       "      <th>Isresolved_No</th>\n",
       "      <th>Isresolved_UNKNOWN</th>\n",
       "      <th>Isresolved_Yes</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_BB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_MB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_TB</th>\n",
       "      <th>Sat_Metric_OverallQoSBox_UNKNOWN</th>\n",
       "      <th>cleaned_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>request phonenumberpii closing utc closing req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fault department opinion faulty design surface...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Verbatim_Length  Isresolved_No  Isresolved_UNKNOWN  Isresolved_Yes  \\\n",
       "0              203              1                   0               0   \n",
       "1              401              1                   0               0   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_BB  Sat_Metric_OverallQoSBox_MB  \\\n",
       "0                            1                            0   \n",
       "1                            1                            0   \n",
       "\n",
       "   Sat_Metric_OverallQoSBox_TB  Sat_Metric_OverallQoSBox_UNKNOWN  \\\n",
       "0                            0                                 0   \n",
       "1                            0                                 0   \n",
       "\n",
       "                                        cleaned_test  \n",
       "0  request phonenumberpii closing utc closing req...  \n",
       "1  fault department opinion faulty design surface...  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = pd.concat([data_dum1.reset_index(drop=True), test_csv[['cleaned_test']]], axis=1)\n",
    "df_t.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 211990/211990 [00:08<00:00, 24925.94it/s]\n"
     ]
    }
   ],
   "source": [
    "test_csv=test_csv[test_csv['cleaned_test'].notnull()]\n",
    "Test_wv_X1 = prepare_sequence(df_t['cleaned_test'], word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_t.drop(['cleaned_test'],axis=True)\n",
    "X_test_set=[]\n",
    "X_test_f1 = np.concatenate([df_t.values, Test_wv_X1], axis=-1)\n",
    "X_test_set=model.predict(X_test_f1)\n",
    "X_test_pro=[]\n",
    "X_test_pro=model.predict_proba(X_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7   , 0.15  , 0.15  ],\n",
       "       [0.85  , 0.0875, 0.0625],\n",
       "       [0.85  , 0.0875, 0.0625],\n",
       "       ...,\n",
       "       [0.6125, 0.225 , 0.1625],\n",
       "       [0.2125, 0.2375, 0.55  ],\n",
       "       [0.075 , 0.0625, 0.8625]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['Predicted Sentiment']=X_test_set\n",
    "test_csv['Predicted Probability']=X_test_pro.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentNumber</th>\n",
       "      <th>Verbatim</th>\n",
       "      <th>Sat_Metric_OverallQoSBox</th>\n",
       "      <th>Isresolved</th>\n",
       "      <th>Verbatim_Length</th>\n",
       "      <th>date</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "      <th>Predicted Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1501886938</td>\n",
       "      <td>Support request No. : \"Phonenumberpii\"    ...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>203</td>\n",
       "      <td>12:20.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[0.7, 0.15, 0.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>This is not the fault of the service depart...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>401</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[0.85, 0.0875, 0.0625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>This is not the fault of the service depart...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>398</td>\n",
       "      <td>29:34.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[0.85, 0.0875, 0.0625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>&lt;**EMAIL ADDRESS REMOVED**&gt;  {Namepii} {Name...</td>\n",
       "      <td>TB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>284</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[0.125, 0.1, 0.775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.20E+14</td>\n",
       "      <td>- average: There were no strong time constrai...</td>\n",
       "      <td>MB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>289</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[0.375, 0.275, 0.35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211985</th>\n",
       "      <td>1.19e+14</td>\n",
       "      <td>{Namepii} figure it out the issue in his first...</td>\n",
       "      <td>TB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[0.25, 0.225, 0.525]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211986</th>\n",
       "      <td>1.2e+14</td>\n",
       "      <td>{Namepii} and devlin Helped on the case Specia...</td>\n",
       "      <td>MB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>70</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[0.2875, 0.1875, 0.525]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211987</th>\n",
       "      <td>1.2e+14</td>\n",
       "      <td>All I needed was an invoice which you were una...</td>\n",
       "      <td>BB</td>\n",
       "      <td>No</td>\n",
       "      <td>106</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[0.6125, 0.225, 0.1625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211988</th>\n",
       "      <td>1.2e+14</td>\n",
       "      <td>{Namepii} this case was sent to a wrong team b...</td>\n",
       "      <td>TB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>115</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[0.2125, 0.2375, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211989</th>\n",
       "      <td>1.2e+14</td>\n",
       "      <td>Wonderful experience working  with your associ...</td>\n",
       "      <td>TB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>103</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[0.075, 0.0625, 0.8625]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211990 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IncidentNumber                                           Verbatim  \\\n",
       "0          1501886938      Support request No. : \"Phonenumberpii\"    ...   \n",
       "1            1.20E+14     This is not the fault of the service depart...   \n",
       "2            1.20E+14     This is not the fault of the service depart...   \n",
       "3            1.20E+14    <**EMAIL ADDRESS REMOVED**>  {Namepii} {Name...   \n",
       "4            1.20E+14   - average: There were no strong time constrai...   \n",
       "...               ...                                                ...   \n",
       "211985       1.19e+14  {Namepii} figure it out the issue in his first...   \n",
       "211986        1.2e+14  {Namepii} and devlin Helped on the case Specia...   \n",
       "211987        1.2e+14  All I needed was an invoice which you were una...   \n",
       "211988        1.2e+14  {Namepii} this case was sent to a wrong team b...   \n",
       "211989        1.2e+14  Wonderful experience working  with your associ...   \n",
       "\n",
       "       Sat_Metric_OverallQoSBox Isresolved  Verbatim_Length     date  \\\n",
       "0                            BB         No              203  12:20.0   \n",
       "1                            BB         No              401  00:00.0   \n",
       "2                            BB         No              398  29:34.0   \n",
       "3                            TB        Yes              284  00:00.0   \n",
       "4                            MB        Yes              289  00:00.0   \n",
       "...                         ...        ...              ...      ...   \n",
       "211985                       TB        Yes               86  00:00.0   \n",
       "211986                       MB        Yes               70  00:00.0   \n",
       "211987                       BB         No              106  00:00.0   \n",
       "211988                       TB        Yes              115  00:00.0   \n",
       "211989                       TB        Yes              103  00:00.0   \n",
       "\n",
       "       Predicted Sentiment    Predicted Probability  \n",
       "0                 Negative        [0.7, 0.15, 0.15]  \n",
       "1                 Negative   [0.85, 0.0875, 0.0625]  \n",
       "2                 Negative   [0.85, 0.0875, 0.0625]  \n",
       "3                 Positive      [0.125, 0.1, 0.775]  \n",
       "4                 Negative     [0.375, 0.275, 0.35]  \n",
       "...                    ...                      ...  \n",
       "211985            Positive     [0.25, 0.225, 0.525]  \n",
       "211986            Positive  [0.2875, 0.1875, 0.525]  \n",
       "211987            Negative  [0.6125, 0.225, 0.1625]  \n",
       "211988            Positive   [0.2125, 0.2375, 0.55]  \n",
       "211989            Positive  [0.075, 0.0625, 0.8625]  \n",
       "\n",
       "[211990 rows x 8 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.drop(['cleaned_test'],axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.to_csv('Production_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_pro=[]\n",
    "#X_test_pro=model.predict_proba(X_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.125, 0.1  , 0.775])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pro[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Sentiment_Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
